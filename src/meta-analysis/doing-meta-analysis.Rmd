---
title: "Doing Meta-Analysis in R"
subtitle: "A Hands-on Guide"
author: ""
date: '`r Sys.Date()`'
# bibliography: references.bib
# link-citations: true
# zotero: "My Library"
# abstract: \singlespacing Abstract which has to be long enough to 
#   take multiple lines otherwise one does not see the effect of single-spacing.
output: 
    html_document:
        number_sections: TRUE
        fig_caption: TRUE
        toc: TRUE
        toc_depth: 5
        toc_float: TRUE
        theme:
            bootswatch: yeti  # minty, flatly, litera, lumen, sandstone, spacelab, yeti
            # bootswatch: cosmo
        highlight: espresso  # espresso, tango, zenburn
        code_folding: show
        # code_download: TRUE
        fig_width: 15
editor_options: 
    chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
# knitr::opts_knit$set(root.dir = ".")  # modify with the location of code
```

***

# Preparations {.tabset .tabset-fade .tabset-pills}
## Packages
```{r Packages, echo=FALSE, message=FALSE}
# Data manipulation
library(tidyverse)
library(data.table)
library(janitor)  # janitor::row_to_names()
library(DT)
library(stringr)  # in tidyverse
library(lubridate)  # in tidyverse

# Visualisation
library(ggplot2)  # RColorBrewer::display.brewer.all()
library(ggalt)  # geom_encircle
library(ggimage)  # geom_subview
library(patchwork)
library(broman)  # plot_crayons()
library(ggsci)  # Journal palette
library(rcartocolor)  # display_carto_all(); https://bit.ly/3Itq5kB
library(PrettyCols)  # view_all_palettes(colourblind_friendly = TRUE)
library(extrafont)  # fonttable(); "Candara"
library(latex2exp)  # example: latex2exp::TeX("Equation: $\\lambda$")

# Descriptive Statistics
library(mice)
library(ggmice)  # see src/imputation/ggmice_XX.Rmd
library(psych)
library(gtsummary)  # tbl_summary; tbl_regression; https://cran.r-project.org/web/packages/gtsummary/vignettes/tbl_regression.html


pacman::p_load(meta, metafor, esc, dmetar)
```

## Environment
```{r Environment, echo=FALSE, message=FALSE}
source(file = "utility/environments.R")
source(file = "utility/helper_functions.R")

fn.prefix <- "doing-meta-analysis_"
```


# Effect Sizes {.tabset .tabset-fade .tabset-pills}
## Mean Difference and Standardized Mean Difference
### Between-Group Mean Difference
$$
MD_{between} = \bar{x}_1 - \bar{x}_2 \\
SE_{MD_{between}} = s_{pooled} \; \sqrt{\frac{1}{n_1} + \frac{1}{n_2}} \\
s_{pooled} = \sqrt{\frac{S^2_{x_1} + S^2_{x_2}}{n_1 + n_2 - 2}} \\
$$

### Between-Group Standardized Mean Difference (SMD; Cohen's d)
- SMD ~ 0.2: small effect
- SMD ~ 0.5: moderate effect
- SMD ~ 0.8: large effect
$$
SMD_{between} = \frac{\bar{x}_1 - \bar{x}_2}{s_{pooled}} \\
SE_{SMD_{between}} = \sqrt{\frac{n_1 + n_2}{n_1 \; n_2} + \frac{SMD^2_{between}}{2 \; (n_1 + n_2)}}
$$

- Not necessary to do these calculations manually like we did here. For a meta-analysis of mean differences, we only have to prepare the following columns in our data set:
`n.e.` The number of observations in the intervention/experimental group.  
`mean.e.` The mean of the intervention/experimental group.  
`sd.e.` The standard deviation in the intervention/experimental group.  
`n.c.` The number of observations in the control group.  
`mean.c.` The mean of the control group.  
`sd.c.` The standard deviation in the control group.  

```{r}
# Define the data we need to calculate SMD/d
# This is just some example data that we made up
grp1m <- 50   # mean of group 1
grp2m <- 60   # mean of group 2
grp1sd <- 10  # sd of group 1
grp2sd <- 10  # sd of group 2
grp1n <- 100  # n of group1
grp2n <- 100  # n of group2

# Calculate effect size
esc_mean_sd(
    grp1m = grp1m,
    grp2m = grp2m,
    grp1sd = grp1sd,
    grp2sd = grp2sd,
    grp1n = grp1n,
    grp2n = grp2n
)
```


# Effect Size Correction
## Small Sample Bias (Hedges' g)
- The standardized mean difference has been found to have an upward bias when the sample size of a study is small, especially when $n \le 20$.
- So it is sensible to correct an upward bias for the standardized mean differences, using Hedges' $g$ formula: 
$$
g = SMD \times (1 - \frac{3}{4n-9})
$$
- $n$ represents the total sample size of study.
```{r}
# Define uncorrected SMD and sample size n
SMD <- 0.5
n <- 30
g <- hedges_g(SMD, n)
g
```



# Pooling Effect Sizes {.tabset .tabset-fade .tabset-pills}
## The Fixed-Effect Model
- All studies are part of a homogeneous population and that the only cause for differences in observed effects is the sampling error of studies. **If we were to calculate the effect size of each study without sampling error, all true effect sizes would be absolutely the same.**
- The only reason why a study $k$'s observed effect size $\hat{\theta}_{k}$ deviates from $\theta$ is because of its sampling error $\epsilon_k$. $\hat{\theta}_{k} = \theta + \epsilon_k$
- All studies are estimators of the same true effect size. Yet, because every study can only draw somewhat bigger or smaller samples of the infinitely large study population, results are burdened by sampling error.
  
  
**Inverse-variance weighting**
$$
w_k = \frac{1}{s_k^2} \\
\hat{\theta} = \frac{\Sigma^K_{k=1} \; \hat{\theta}_k \; w_k}{\Sigma^K_{k=1} \; w_k}
$$
```{r}
data(SuicidePrevention)

# Calculate Hedges' g effect sizes and the standard errors for pooling.
# - We save the study names in "study".
# - We use the pmap_dfr function to calculate the effect size for each row.
SP_calc <- pmap_dfr(SuicidePrevention, 
                    function(mean.e, sd.e, n.e, mean.c,
                             sd.c, n.c, author, ...){
                        esc_mean_sd(
                            grp1m = mean.e, grp1sd = sd.e, grp1n = n.e, 
                            grp2m = mean.c, grp2sd = sd.c, grp2n = n.c, 
                            study = author, 
                            es.type = "g"  # Hedges' g
                        ) %>% as.data.frame()
                    }) 

# The data set contains Hedges' g ("es") and standard error ("se")
SP_calc
```
```{r}
# Calculate the inverse variance-weights for each study
SP_calc$w <- 1 / SP_calc$se ^ 2

# Then, we use the weights to calculate the pooled effect
pooled_effect <- sum(SP_calc$w * SP_calc$es) / sum(SP_calc$w)
pooled_effect
```

## The Random-Effects Model
- The random-effects model assumes that there is not only one true effect size $\theta$ but a distribution of true effect sizes $\theta_k$. 
- The goal of the random-effects model is therefore **not** to estimate the one true effect size $\theta$ of all studies, but the mean of the distribution of true effects $\theta_k$.

$$
\hat{\theta}_{k} = \theta_k + \epsilon_k \neq \theta + \epsilon_k \\
\theta_{k} = \mu + \zeta_{k}
$$

## Estimators of the Betweeen-Study Heterogeneity

**Inverse-variance weighting**  
$\tau^2$: The variance of the distribution of true effect sizes
$$
w_k^* = \frac{1}{s_k^2 + \tau^2} \\
\hat{\theta} = \frac{\Sigma^K_{k=1} \; \hat{\theta}_k \; w_k^*}{\Sigma^K_{k=1} \; w_k^*}
$$

For estimate $\hat{\theta}$, we also have to estimate the variance of the distribution of true effect sizes $\tau^2$ before that.
  
Which Estimator Should I Use?
(https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/pooling-es.html#rem)
- Continuous: REML
- Binary: Paule-Mandel
- Large heterogeneity: Sidik-Jonkman
- Outside R: Dersimonian-Laird

## Significance Tests using Knapp-Hartung Adjustments
- Several studies showed that Knapp-Hartung adjustments can reduce the chance of false positives, especially when the number of studies is small.
- While significance tests of the pooled effect usually assume a normal distribution (so-called Wald-type tests), the Knapp-Hartung method is based on a t distribution.


# Effect Size Pooling in R
```{r}
data(ThirdWave)
glimpse(ThirdWave)
```


# Power Analysis
```{r}
power.analysis(
    d = 0.2,
    k = 10,
    n1 = 25,
    n2 = 25,
    p = 0.05
)
```
```{r}
power.analysis(
    d = 0.5,
    k = 10,
    n1 = 25,
    n2 = 25,
    p = 0.05,
    heterogeneity = "moderate"
)
```



# References
- https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/
