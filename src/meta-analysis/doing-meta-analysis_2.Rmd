---
title: "Doing Meta-Analysis in R"
subtitle: "Section 5 - 9"
author: ""
date: '`r Sys.Date()`'
# bibliography: references.bib
# link-citations: true
# zotero: "My Library"
# abstract: \singlespacing Abstract which has to be long enough to 
#   take multiple lines otherwise one does not see the effect of single-spacing.
output: 
    html_document:
        number_sections: TRUE
        fig_caption: TRUE
        toc: TRUE
        toc_depth: 5
        toc_float: TRUE
        theme:
            bootswatch: yeti  # minty, flatly, litera, lumen, sandstone, spacelab, yeti
            # bootswatch: cosmo
        highlight: espresso  # espresso, tango, zenburn
        code_folding: show
        # code_download: TRUE
        fig_width: 15
editor_options: 
    chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
# knitr::opts_knit$set(root.dir = ".")  # modify with the location of code
```

***

# Preparations {.tabset .tabset-fade .tabset-pills}
## Packages
```{r Packages, echo=FALSE, message=FALSE}
# Data manipulation
library(tidyverse)
library(data.table)
library(janitor)  # janitor::row_to_names()
library(DT)
library(stringr)  # in tidyverse
library(lubridate)  # in tidyverse

# Visualisation
library(ggplot2)  # RColorBrewer::display.brewer.all()
library(ggalt)  # geom_encircle
library(ggimage)  # geom_subview
library(patchwork)
library(broman)  # plot_crayons()
library(ggsci)  # Journal palette
library(rcartocolor)  # display_carto_all(); https://bit.ly/3Itq5kB
library(PrettyCols)  # view_all_palettes(colourblind_friendly = TRUE)
library(extrafont)  # fonttable(); "Candara"
library(latex2exp)  # example: latex2exp::TeX("Equation: $\\lambda$")
library(GGally)  # https://ggobi.github.io/ggally/reference/index.html

# Descriptive Statistics
library(mice)
library(ggmice)  # see src/imputation/ggmice_XX.Rmd
library(psych)
library(gtsummary)  # tbl_summary; tbl_regression; https://cran.r-project.org/web/packages/gtsummary/vignettes/tbl_regression.html


pacman::p_load(meta, metafor, esc, dmetar)
```

## Environment
```{r Environment, echo=FALSE, message=FALSE}
source(file = "utility/environments.R")
source(file = "utility/helper_functions.R")

fn.prefix <- "doing-meta-analysis_"
```

# Between-Study Heterogeneity {.tabset .tabset-fade .tabset-pills}
## Cochran's Q
- $Q$ increases both when the number of studies $K$, and when the precision (i.e. the sample size of a study) increases. Therefore, $Q$ and whether it is significant highly depends on the size of your meta-analysis, and thus its statistical power.
- From this follows that we should not only rely on the significance of a $Q$-test when assessing heterogeneity.
- $\hat{\theta}$: the pooled effect according to the fixed-effect model.

$$
Q = \sum^{K}_{k=1} \; w_k \; (\hat{\theta}_k - \hat{\theta})^2 \\
w_k = \frac{1}{s_k^2}
$$
$\hat{\theta}$: the pooled effect according to the `fixed-effect` model.

Case 1: no-heterogeneity
$\zeta_k = 0$ and the residuals $\hat{\theta_k} - \hat{\theta}$ are only product of the sampling error $\epsilon_k$.
$$
\hat{\theta}_k - \hat{\theta} \sim N(0, \; 1)
$$
```{r}
set.seed(2024)
error_fixed <- replicate(n = 10000, rnorm(40))
```

Case 2: heterogeneity
Reference: https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/pooling-es.html#rem
$$
\hat{\theta}_k - \hat{\theta} = \epsilon_k + \zeta_k
$$
```{r}
set.seed(2024)
error_random <- replicate(n = 10000, rnorm(40) + rnorm(40))
```

Simplify the formula of $Q$ a little by assuming that the variance, and thus the weight 
$w_k$ of every study, is one, resulting in $w_k$ to drop out of the equation. 
```{r}
set.seed(2024)
Q_fixed <- replicate(10000, sum(rnorm(40)^2))
Q_random <- replicate(10000, sum((rnorm(40) + rnorm(40))^2))
```
```{r}
hist(error_fixed, 
     xlab = expression(hat(theta[k]) ~ - ~ hat(theta)), prob = TRUE, 
     breaks = 100, ylim = c(0, .45), xlim = c(-4, 4), 
     main = "No Heterogeneity")
lines(seq(-4, 4, 0.01), dnorm(seq(-4, 4, 0.01)), 
      col = "blue", lwd = 2)

hist(error_random, 
     xlab = expression(hat(theta[k]) ~ - ~ hat(theta)), prob = TRUE, 
     breaks = 100, ylim = c(0, .45), xlim = c(-4, 4), 
     main = "Heterogeneity")
lines(seq(-4, 4, 0.01), dnorm(seq(-4, 4, 0.01)), 
      col = "blue", lwd = 2)

df <- 40 - 1
hist(Q_fixed, xlab = expression(italic("Q")), prob = TRUE, 
     breaks = 100, ylim = c(0, .06), xlim = c(0, 160), 
     main = "No Heterogeneity")
lines(seq(0, 100, 0.01), dchisq(seq(0, 100, 0.01), df = df), 
      col = "blue", lwd = 2)

hist(Q_random,  xlab = expression(italic("Q")), prob = TRUE, 
     breaks = 100, ylim = c(0, .06), xlim = c(0, 160), 
     main = "Heterogeneity")
lines(seq(0, 150, 0.01), dchisq(seq(0, 150, 0.01), df = df * 2), 
      col = "blue", lwd = 2)
```

## Higgins & Thompson's I^2 Statistic
- Defined as the percentage of variability in the effect sizes that is not caused by sampling error.
- It quantifies, in percent, how much the observed value of $Q$ exceeds the expected 
$Q$ value when there is no heterogeneity (i.e. K - 1)
$$
I^2 = \frac{Max\{Q - (K - 1), \; 0\}}{Q} \ge 0
$$
```{r}
hist((Q_fixed - 39) / Q_fixed, breaks = 100)
```
```{r}
hist((Q_random - 39) / Q_random, breaks = 100)
```

## The H^2 Statistic
- A little more elegant than the one of $I^2$, because we do not have to artificially correct its value when $Q$ is smaller than $K - 1$.
- Values greater than one indicate the presence of between-study heterogeneity.
- Compared to $I^2$, it is far less common to find this statistic reported in published meta-analyses.
$$
H^2 = \frac{Q}{K-1}
$$

## Q-Profile
- The Q-Profile method is based on an altered $Q$ version, the generalized Q-statistic $Q_{gen}$.
- While the standard version of $Q$ uses the pooled effect based on the fixed-effect model, $Q_{gen}$ is based on the random-effects model.
- $\hat{u}$: the overall effect according to the random-effects model
- The Q-Profile method can be specified in `meta` functions through the argument `method.tau.ci = "QP"`. This is the default setting.
- $Q_{gen}(\tilde{\tau}^2)$ is calculated repeatedly while increasing the value of $\tau^2$, until the expected value of the lower and upper bound of the confidence interval based on the $\chi^2$ distribution ($K-1$ DoF) is reached.

$$
Q_{gen} = \sum^{K}_{k=1} \; w_k^* \; (\hat{\theta}_k - \hat{u})^2 \\
w_k^* = \frac{1}{s_k^2 \; + \; \tau^2}
$$

## Prediction Intervals (PIs)
- A good way to overcome limitation of other measures (become significant when studies have a greater sample size).
- Give us a range into which we can expect the effects of future studies to fall based on present evidence.
- To calculate prediction intervals around the overall effect $\hat{u}$, we use both the estimated between-study heterogeneity variance $\hat{\tau}^2$, as well as the standard error of the pooled effect, $SE_{\hat{u}}$.
- When running a meta-analysis, we have to add the argument `prediction = TRUE` so that prediction intervals appear in the output.
$$
\hat{u} \; \pm \; t_{K-1, 0.975} \; \sqrt{SE^2_{\hat{u}} \; + \; \hat{\tau}^2} \\
\hat{u} \; \pm \; t_{K-1, 0.975} \; SD_{PI}
$$

## Assesing Heterogeneity in R
```{r}
data(ThirdWave)
m.gen <- metagen(TE = TE,
                 seTE = seTE,
                 studlab = Author,
                 data = ThirdWave,
                 sm = "SMD",
                 fixed = FALSE,
                 random = TRUE,
                 method.tau = "REML",
                 method.random.ci = "HK",
                 title = "Third Wave Psychotherapies")
```

```{r}
m.gen <- update(m.gen, prediction = TRUE)
summary(m.gen)
```


## Outliers and Influential Cases
- Assessing the robustness of our pooled results: outlier and influence analyses.

### Basic Outlier Removal
- View a study as an outlier if its confidence interval does not overlap with the confidence interval of the pooled effect.
```{r}
m.gen.rem <- dmetar::find.outliers(m.gen)
summary(m.gen.rem)
summary(m.gen.rem$m.random)
```

### Influence Analysis
- When find an overall effect in our meta-analysis, but its significance depends on a single large study. This would mean that the pooled effect is not statistically significant anymore once the influential study is removed.
- Based on the `leave-one-out (LOO)` method, we recalculate the results of our meta-analysis K times, each time leaving out one study.
- The `InfluenceAnalysis` function creates four influence diagnostic plots: `a Baujat plot`, `influence diagnostics according to Viechtbauer and Cheung (2010)`, and `the leave-one-out meta-analysis results, sorted by effect size and I^2 value`. 
```{r}
m.gen.inf <- InfluenceAnalysis(m.gen, random = TRUE)
summary(m.gen.inf)
```

#### Baujat Plot
- The plot shows the contribution of each study to `the overall heterogeneity` (as measured by Cochran's $Q$) on the horizontal axis, and its `influence on the pooled effect size` on the vertical axis.
- The influence value is determined through the LOO method, and expresses the standardized difference of the overall effect when the study is included in the meta-analysis, versus when it is not included.
- Studies on the right side of the plot can be regarded as potentially relevant cases since they contribute heavily to the overall heterogeneity in our meta-analysis (already detected before: DanitzOrsillo and Shairo et al.)
```{r}
plot(m.gen.inf, "baujat")
```

#### Influence Diasgnostics
- Reference: 
https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/heterogeneity.html#inf-diags
- Studies determined to be influential are displayed in red in the plot generated by the `InfluenceAnalysis` function **based on the rules of thumb**.
$$
\mathrm{DFFITS}_k > 3 \sqrt{\frac{1}{k-1}} \\
D_k > 0.45
$$
```{r}
plot(m.gen.inf, "influence")
```


#### LOO Meta-Analysis Results
```{r}
plot(m.gen.inf, "es")  # effect size
```
```{r}
plot(m.gen.inf, "i2")  # Higgins & Thompson's I^2
```

### GOSH Plot Analysis
- Fit the same meta-analysis model to all possible subsets of our included studies. In contrast to the leave-one-out method, we therefore not only fit K models, but a model for all $2^{k-1}$ possible study combinations. But this means quite computationally expensive.
- The R implementation we cover here only fits a maximum of 1 million randomly selected models.
```{r}
m.rma <- rma(yi = m.gen$TE,
             sei = m.gen$seTE,
             method = m.gen$method.tau,
             test = "knha")
```

```{r}
res.gosh <- gosh(m.rma)
```

```{r}
plot(res.gosh, alpha = 0.01)
```

- The `gosh.diagnostics` function uses `three cluster algorithms` to detect patterns in our data: the k-means algorithm (Hartigan and Wong 1979), density reachability and connectivity clustering, or DBSCAN (Schubert et al. 2017) and gaussian mixture models (Fraley and Raftery 2002).
```{r}
res.gosh.diag <- gosh.diagnostics(res.gosh, 
                                  km.params = list(centers = 2), 
                                  db.params = list(eps = 0.08, 
                                                   MinPts = 50))
res.gosh.diag
```

```{r}
plot(res.gosh.diag)
```

```{r}
update(m.gen, exclude = c(3, 4, 16)) %>% summary()
```

Let us assume we determined influential studies in our meta-analysis. In this case, it makes sense to also report the results of a sensitivity analysis in which these studies are excluded. To make it easy for readers to see the changes associated with removing the influential studies, we can create a table in which both the original results, as well as the results of the sensitivity analysis are displayed.


# Forest Plots
- A diamond shape represents the average effect. The length of the diamond symbolizes the confidence interval of the pooled result on the x-axis. 
- When the summary measure is a ratio (such as odds ratios or risk ratios), it is common to use a logarithmic scale on the x-axis. 
- "RevMan5" is a software name develped by Cochrane
```{r}
png(file = "fig/doing-meta-analysis_2-1.png", 
    width = 3600, height = 2400, res = 300)

meta::forest(m.gen, 
             sortvar = TE, 
             layout = "RevMan5",  # Cochrane's Review Manager 5
             xlim = c(floor(min(m.gen$lower)), ceiling(max(m.gen$upper))), 
             prediction = TRUE, 
             print.I2 = TRUE, 
             print.I2.ci = TRUE, 
             print.tau2 = TRUE, 
             print.tau2.ci = TRUE, 
             # smlab = m.gen$sm, 
             label.left = NULL, 
             col.square = col.tw,
             col.square.line = col.bmc.sky, 
             col.diamond = col.bmc.pink,
             # col.diamond.common = col.bmc.pink, 
             col.diamond.random = col.tw, 
             col.diamond.lines = col.bmc.pink, 
             col.predict = col.sl, 
             col.predict.lines = col.bmc.pink, 
             # leftcols = c("studlab", "TE", "seTE", "RiskOfBias"),
             # leftlabs = c("Author", "g", "SE", "Risk of Bias"),
             fontfamily = "Times New Roman", 
             colgap = "15mm")
dev.off()
```


# Drapery Plots
- Drapery plots are based on p-value functions. Such p-value functions have been proposed to prevent us from solely relying on the p<0.05 significance threshold when interpreting the results of an analysis.
- Therefore, instead of only calculating the 95% confidence interval, p-value functions provide a continuous curve which shows the confidence interval for varying values of p.
```{r}
drapery(m.gen,
        labels = "studlab",
        type = "pval",
        legend = FALSE)
```


# Subgroup Analyses
## The Fixed-Effects Plural Model (Mixed-Effects Model)
- `A meta-ragression (mixed-effects model) with a categorical predictor`. 
$$
D_g = 0 \; (\mathrm{Subgroup \; A}) \\
D_g = 1 \; (\mathrm{Subgroup \; B}) \\
\hat{\theta_k} = \theta + \beta \; D_g + \epsilon_k + \zeta_k
$$
$\theta$: the intercept in our regression model. the true overall effect size of subgroup A  
$\beta$: the effect size difference between subgroup A and subgroup B.  

- An objective is to reject the null hypothesis that there is no difference in effect sizes between subgroups (e.g. $Q$ test), `regarding the pooled effect of a subgroup as the observed effect size of one large study`.
- The difference to a normal meta-analysis is that we conduct several separate random-effects meta-analyses, one for each subgroup. Studies within a subgroup are drawn from a universe of populations, the mean of which we want to estimate. 
- Since each subgroup gets its own separate meta-analysis, estimated heterogeneity $\hat{\tau_g}^2$ will also differ from subgroup to subgroup.
- When the number of studies in a subgroup is small (< 5), it is better to calculate a pooled version of $\tau^2$ that is used across all subgroups, than to rely on a very imprecise estimate of the between-study heterogeneity in one subgroup $\hat{\tau_g}^2$.
- At least K=10 studies are required to do subgroup analyses in each group.
  
![The Fixed-Effects Plural Model](https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/images/subgroups_sep.png)
```{r}
update(m.gen, 
       subgroup = RiskOfBias, 
       tau.common = FALSE)
```


# Meta-Regression (Mixed-Effects Model)
$$
\hat{\theta}_k = \theta + \beta \; x_k + \epsilon_k + \zeta_k
$$

- Perform a regression with predictors on a study level.
- Subgroup analysis is a meta-regression with a categorical predictor. 
- The random-effects model to pool effect sizes is nothing but a meta-regression model without a slope term, $\beta$.
- In meta-regression, a modified method called weighted least squares (WLS) is used, which makes sure that studies with a smaller standard error are given a higher weight.
- $R^2$ in meta-regression is slightly different to the one used in conventional regressions. $R^2_*$ uses the amount of residual heterogeneity variance that even the meta-regression slope cannot explain, and puts it in relation to the total heterogeneity that we initially found in our meta-analysis.

$$
R^2_* = 1 - \frac{\hat{\tau}^2_{unexplained}}{\hat{\tau}^2_{(total)}}
$$

![Meta-regression with a continuous predictor and four studies](https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/images/subgroups3_sep.png)

```{r}
# Add the publication years to ThirdWave dataset.
year <- c(2014, 1998, 2010, 1999, 2005, 2014, 
          2019, 2010, 1982, 2020, 1978, 2001, 
          2018, 2002, 2009, 2011, 2011, 2013)
m.gen.reg <- metareg(m.gen, ~ year)
```

We are also presented with the corresponding t-statistic for each regression coefficient (tval). This tells us that the Knapp-Hartung method was used to calculate the confidence interval and p-value. Since we also used this adjustment in our initial meta-analysis model, metareg automatically used it again here. Otherwise, z values and Wald-type confidence intervals would have been provided.
```{r}
m.gen.reg
```

## A Bubble Plot
- Shows the estimated regression slope, as well as the effect size of each study. 
```{r}
bubble(m.gen.reg, studlab = TRUE)
```

## Subgroup Analysis within a Meta-regression Framework
- The results are identical to the ones of a subgroup analysis which assumes a common estimate of $\tau^2$.
```{r}
metareg(m.gen, RiskOfBias)
```

## Multiple Meta-Regression in R
- The function `rma` runs a random-effects meta-analysis, which is extended to mixed-effects meta-regression models when moderators are added.
- We can use the `anova` function, providing it with the two models we want to compare. Note that this is only feasible because we fitted both mixed-effects models using maximum likelihood ("ML") instead of restricted maximum likelihood ("REML").
```{r}
data(MVRegressionData)
glimpse(MVRegressionData)

ggpairs(
    data = MVRegressionData[, c("reputation", "quality", "pubyear")]
) + theme_gray()
```
```{r}
m.qual <- rma(yi = yi, 
              sei = sei, 
              data = MVRegressionData, 
              method = "ML", 
              mods = ~ quality, 
              test = "knha")

m.qual
```
```{r}
m.qual.rep <- rma(yi = yi, 
                  sei = sei, 
                  data = MVRegressionData, 
                  method = "ML", 
                  mods = ~ quality + reputation, 
                  test = "knha")

m.qual.rep
```

### Model Selection
```{r}
# The anova function performs a likelihood ratio test, the results of which we can see in the `LRT` column. log-likelihood ratio ~ chisq(df1 - df2)
# log-likelihood ratio = 2 * (LL_1 - LL_0) = 2 * log(L_1 / L_0)
anova(m.qual, m.qual.rep)
```

### Permutation Test
```{r}

```


# Power Analysis {.tabset .tabset-fade .tabset-pills}
```{r}
power.analysis(
    d = 0.2,
    k = 10,
    n1 = 25,
    n2 = 25,
    p = 0.05
)
```
```{r}
power.analysis(
    d = 0.5,
    k = 10,
    n1 = 25,
    n2 = 25,
    p = 0.05,
    heterogeneity = "moderate"
)
```


# References
- https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/
- Bakbergenuly, Ilyas, David C. Hoaglin, and Elena Kulinskaya. 2020. “Methods for Estimating Between-Study Variance and Overall Effect in Meta-Analysis of Odds Ratios.” Research Synthesis Methods 11(3): 426–42. doi:10.1002/jrsm.1404.
