---
title: "Doing Meta-Analysis in R"
subtitle: "Section 1 - 4"
author: ""
date: '`r Sys.Date()`'
# bibliography: references.bib
# link-citations: true
# zotero: "My Library"
# abstract: \singlespacing Abstract which has to be long enough to 
#   take multiple lines otherwise one does not see the effect of single-spacing.
output: 
    html_document:
        number_sections: TRUE
        fig_caption: TRUE
        toc: TRUE
        toc_depth: 5
        toc_float: TRUE
        theme:
            bootswatch: yeti  # minty, flatly, litera, lumen, sandstone, spacelab, yeti
            # bootswatch: cosmo
        highlight: espresso  # espresso, tango, zenburn
        code_folding: show
        # code_download: TRUE
        fig_width: 15
editor_options: 
    chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
# knitr::opts_knit$set(root.dir = ".")  # modify with the location of code
```

***

# Preparations {.tabset .tabset-fade .tabset-pills}
## Packages
```{r Packages, echo=FALSE, message=FALSE}
# Data manipulation
library(tidyverse)
library(data.table)
library(janitor)  # janitor::row_to_names()
library(DT)
library(stringr)  # in tidyverse
library(lubridate)  # in tidyverse

# Visualisation
library(ggplot2)  # RColorBrewer::display.brewer.all()
library(ggalt)  # geom_encircle
library(ggimage)  # geom_subview
library(patchwork)
library(broman)  # plot_crayons()
library(ggsci)  # Journal palette
library(rcartocolor)  # display_carto_all(); https://bit.ly/3Itq5kB
library(PrettyCols)  # view_all_palettes(colourblind_friendly = TRUE)
library(extrafont)  # fonttable(); "Candara"
library(latex2exp)  # example: latex2exp::TeX("Equation: $\\lambda$")

# Descriptive Statistics
library(mice)
library(ggmice)  # see src/imputation/ggmice_XX.Rmd
library(psych)
library(gtsummary)  # tbl_summary; tbl_regression; https://cran.r-project.org/web/packages/gtsummary/vignettes/tbl_regression.html


pacman::p_load(meta, metafor, esc, dmetar)
```

## Environment
```{r Environment, echo=FALSE, message=FALSE}
source(file = "utility/environments.R")
source(file = "utility/helper_functions.R")

fn.prefix <- "doing-meta-analysis_"
```


# Effect Sizes {.tabset .tabset-fade .tabset-pills}
## Mean Difference and Standardized Mean Difference
### Between-Group Mean Difference
$$
MD_{between} = \bar{x}_1 - \bar{x}_2 \\
SE_{MD_{between}} = s_{pooled} \; \sqrt{\frac{1}{n_1} + \frac{1}{n_2}} \\
s_{pooled} = \sqrt{\frac{S^2_{x_1} + S^2_{x_2}}{n_1 + n_2 - 2}} \\
$$

### Between-Group Standardized Mean Difference (SMD; Cohen's d)
- SMD ~ 0.2: small effect
- SMD ~ 0.5: moderate effect
- SMD ~ 0.8: large effect
$$
SMD_{between} = \frac{\bar{x}_1 - \bar{x}_2}{s_{pooled}} \\
SE_{SMD_{between}} = \sqrt{\frac{n_1 + n_2}{n_1 \; n_2} + \frac{SMD^2_{between}}{2 \; (n_1 + n_2)}}
$$

- Not necessary to do these calculations manually like we did here. For a meta-analysis of mean differences, we only have to prepare the following columns in our data set:
`n.e.` The number of observations in the intervention/experimental group.  
`mean.e.` The mean of the intervention/experimental group.  
`sd.e.` The standard deviation in the intervention/experimental group.  
`n.c.` The number of observations in the control group.  
`mean.c.` The mean of the control group.  
`sd.c.` The standard deviation in the control group.  

```{r}
# Define the data we need to calculate SMD/d
# This is just some example data that we made up
grp1m <- 50   # mean of group 1
grp2m <- 60   # mean of group 2
grp1sd <- 10  # sd of group 1
grp2sd <- 10  # sd of group 2
grp1n <- 100  # n of group1
grp2n <- 100  # n of group2

# Calculate effect size
esc_mean_sd(
    grp1m = grp1m,
    grp2m = grp2m,
    grp1sd = grp1sd,
    grp2sd = grp2sd,
    grp1n = grp1n,
    grp2n = grp2n
)
```


# Effect Size Correction
## Small Sample Bias (Hedges' g)
- The standardized mean difference has been found to have an upward bias when the sample size of a study is small, especially when $n \le 20$.
- So it is sensible to correct an upward bias for the standardized mean differences, using Hedges' $g$ formula: 
$$
g = SMD \times (1 - \frac{3}{4n-9})
$$
- $n$ represents the total sample size of study.
```{r}
# Define uncorrected SMD and sample size n
SMD <- 0.5
n <- 30
g <- hedges_g(SMD, n)
g
```



# Pooling Effect Sizes {.tabset .tabset-fade .tabset-pills}
## The Fixed-Effect Model
- All studies are part of a homogeneous population and that the only cause for differences in observed effects is the sampling error of studies. **If we were to calculate the effect size of each study without sampling error, all true effect sizes would be absolutely the same.**
- The only reason why a study $k$'s observed effect size $\hat{\theta}_{k}$ deviates from $\theta$ is because of its sampling error $\epsilon_k$. $\hat{\theta}_{k} = \theta + \epsilon_k$
- All studies are estimators of the same true effect size. Yet, because every study can only draw somewhat bigger or smaller samples of the infinitely large study population, results are burdened by sampling error.
  
  
**Inverse-variance weighting**
$$
w_k = \frac{1}{s_k^2} \\
\hat{\theta} = \frac{\Sigma^K_{k=1} \; \hat{\theta}_k \; w_k}{\Sigma^K_{k=1} \; w_k}
$$
```{r}
data(SuicidePrevention)

# Calculate Hedges' g effect sizes and the standard errors for pooling.
# - We save the study names in "study".
# - We use the pmap_dfr function to calculate the effect size for each row.
SP_calc <- pmap_dfr(SuicidePrevention, 
                    function(mean.e, sd.e, n.e, mean.c,
                             sd.c, n.c, author, ...){
                        esc_mean_sd(
                            grp1m = mean.e, grp1sd = sd.e, grp1n = n.e, 
                            grp2m = mean.c, grp2sd = sd.c, grp2n = n.c, 
                            study = author, 
                            es.type = "g"  # Hedges' g
                        ) %>% as.data.frame()
                    }) 

# The data set contains Hedges' g ("es") and standard error ("se")
SP_calc
```
```{r}
# Calculate the inverse variance-weights for each study
SP_calc$w <- 1 / SP_calc$se ^ 2

# Then, we use the weights to calculate the pooled effect
pooled_effect <- sum(SP_calc$w * SP_calc$es) / sum(SP_calc$w)
pooled_effect
```

## The Random-Effects Model
- The random-effects model assumes that there is not only one true effect size $\theta$ but a distribution of true effect sizes $\theta_k$. 
- The goal of the random-effects model is therefore **not** to estimate the one true effect size $\theta$ of all studies, but the mean of the distribution of true effects $\theta_k$.

$$
\hat{\theta}_{k} = \theta_k + \epsilon_k \neq \theta + \epsilon_k \\
\theta_{k} = \mu + \zeta_{k}
$$

## Estimators of the Betweeen-Study Heterogeneity

**Inverse-variance weighting**  
$\tau^2$: The variance of the distribution of true effect sizes
$$
w_k^* = \frac{1}{s_k^2 + \tau^2} \\
\hat{\theta} = \frac{\Sigma^K_{k=1} \; \hat{\theta}_k \; w_k^*}{\Sigma^K_{k=1} \; w_k^*}
$$

For estimate $\hat{\theta}$, we also have to estimate the variance of the distribution of true effect sizes $\tau^2$ before that.
  
Which Estimator Should I Use?
(https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/pooling-es.html#rem)
- Continuous: REML
- Binary: Paule-Mandel
- Large heterogeneity: Sidik-Jonkman
- Outside R: Dersimonian-Laird (classical and frequently used, but biased)

## Significance Tests using Knapp-Hartung Adjustments
- Several studies showed that Knapp-Hartung adjustments can reduce the chance of false positives, especially when the number of studies is small.
- While significance tests of the pooled effect usually assume a normal distribution (so-called Wald-type tests), the Knapp-Hartung method is based on a t distribution.


# Effect Size Pooling in R {.tabset .tabset-fade .tabset-pills}
## Pre-Calculated Effect Size Data
https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/pooling-es.html#pre-calculated-es  
- Studies examining the effect of so-called "hird wave" psychotherapies on perceived stress in college students.
- The `TE` column contains the g value of each study, and `seTE` is the standard error of g. The other columns represent variables describing the subgroup categories that each study falls into.
```{r}
data(ThirdWave)
glimpse(ThirdWave)
```

```{r}
m.gen <- metagen(TE = TE,  # treatment effect
                 seTE = seTE,  # standard error of TE
                 studlab = Author,  # study labels
                 data = ThirdWave, 
                 sm = "SMD",  # underlying summary measure
                 fixed = FALSE,  # if fixed-effect model meta-analysis should be calc.
                 random = TRUE,  # if a random-effects model should be used.
                 method.tau = "REML",
                 hakn = TRUE,  # Knapp-Hartung adjustments
                 title = "Third Wave Psychotherapies")
summary(m.gen)
```


## SMD
```{r}
data("SuicidePrevention")
```
The variance of true effect sizes is not significantly greater than zero.
```{r}
# ?metacont
m.cont <- metacont(n.e = n.e, 
                   mean.e = mean.e, 
                   sd.e = sd.e, 
                   n.c = n.c, 
                   mean.c = mean.c, 
                   sd.c = sd.c, 
                   studlab = author, 
                   data = SuicidePrevention, 
                   sm = "SMD", 
                   method.smd = "Hedges",  # only relevant when sm = "SMD"
                   fixed = FALSE, 
                   random = TRUE, 
                   method.tau = "REML", 
                   hakn = TRUE,  # Knapp-Hartung adjustments
                   title = "Suicide Prevention")
summary(m.cont)
```


## Binary Outcomes
### Risk and Odds Ratios
### The Mantel-Haenszel Method
- The Mantel-Haenszel Method commonly used as an alternative to calculate the weights of studies with binary outcome data.
- It may be advisable in most cases to follow Cochrane's general assessment (Julian Higgins et al. 2019, chap. 10.4), and use the Mantel-Haenszel method (without continuity correction: add +0.5 to a zero cell).

Risk Ratio:  
$$
w_k = \frac{(a_k + b_k) \; c_k}{n_k}
$$
Odds Ratio:  
$$
w_k = \frac{b_k \; c_k}{n_k}
$$
$a_k$: the number of  events in the treatment group  
$b_k$: the number of  non-events in the treatment group  
$c_k$: the number of  events in the control group  
$d_k$: the number of  non-events in the control group  

### The Peto Method
- The Peto method uses a special kind of effect size, **the Peto odds ratio**, which we will denote with $\hat{\psi_k}$.
$$
O_k = a_k \\
E_k = \frac{(a_k + b_k)(a_k + c_k)}{a_k + b_k + c_k + d_k} \\
V_k = \frac{(a_k + b_k)(c_k + d_k)(a_k + c_k)(b_k + d_k)}{(a_k + b_k + c_k + d_k)^2 \; (a_k + b_k + c_k + d_k - 1)} \\
\log{\hat{\psi_k}} = \frac{O_k - E_k}{V_k}
$$

### The Bakbergenuly-Sample Size Method
- The weight of effects is only determined by a study's sample size.
- It showed that this approach may be preferable to the one by Mantel and Haenszel.
- The weights and overall effect using the fixed- and random-effects model will be identical.
$$
w_k = \frac{n_{treat_k} \; n_{control_k}}{n_{treat_k} + n_{control_k}}
$$

### Pooling Binary Effect Sizes in R
```{r}
data(DepressionMortality)
# View(DepressionMortality)
```
```{r}
m.bin <- metabin(event.e = event.e, 
                 n.e = n.e, 
                 event.c = event.c, 
                 n.c = n.c, 
                 studlab = author, 
                 data = DepressionMortality, 
                 method = "MH",  # Mantel-Haenszel method; decault and recommended
                 sm = "RR",  # RR: risk ratio; OR: odds ratio
                 MH.exact = TRUE,  # TRUE: Do not use a continuity correction for MH
                 fixed = TRUE,  # both fixed and random effects model can be caluculated
                 random = TRUE, 
                 method.tau = "PM",  # Paule-Mandel is a good choice for binary outcomes
                 hakn = TRUE, 
                 title = "Depression and Mortality")
summary(m.bin)
```

Check if the method to estimate $\tau^2$ has an impact on the results.  
Meta-analyses of binary outcomes are actually performed by using a log-transformed version of the effect size. When presenting the results, metabin just reconverts the effect size metrics to their original form through exponentitating the value.
```{r}
m.bin.update <- update.meta(m.bin, method.tau = "REML")
print(exp(m.bin.update$TE.random))
print(m.bin.update$tau2)
```

OR version  
```{r}
m.bin.or <- update.meta(m.bin, sm = "OR")
summary(m.bin.or)
```

### Pooling Pre-Calculated Binary Effect Sizes
- Confidence intervals are ok instead of seTE.
```{r}
DepressionMortality$TE <- m.bin$TE  # log-transformed
DepressionMortality$seTE <- m.bin$seTE  # log-transformed

# Set seTE of study 7 to NA
DepressionMortality$seTE[7] <- NA

# Create empty columns 'lower' and 'upper'
DepressionMortality[,"lower"] <- NA
DepressionMortality[,"upper"] <- NA

# Fill in values for 'lower' and 'upper' in study 7
# As always, binary effect sizes need to be log-transformed
DepressionMortality$lower[7] <- log(1.26)
DepressionMortality$upper[7] <- log(2.46)

DepressionMortality[,c("author", "TE", "seTE", "lower", "upper")]
```
```{r}
m.gen_bin <- metagen(TE = TE, 
                     seTE = seTE, 
                     lower = lower, 
                     upper = upper, 
                     studlab = author, 
                     data = DepressionMortality, 
                     sm = "RR", 
                     method.tau = "PM", 
                     fixed = FALSE, 
                     random = TRUE, 
                     title = "Depression Mortality (Pre-calculated)")

summary(m.gen_bin)
```

### Incidence Rate Ratios
- In contrast to metabin, metainc does not use a continuity correction by default. Specifying MH.exact as TRUE is therefore not required. A continuity correction is only performed when we choose the generic inverse variance pooling method (method = "Inverse").
```{r}
data(EatingDisorderPrevention)
# View(EatingDisorderPrevention)
```
```{r}
m.inc <- metainc(event.e = event.e, 
                 time.e = time.e, 
                 event.c = event.c, 
                 time.c = time.c, 
                 studlab = Author, 
                 data = EatingDisorderPrevention, 
                 sm = "IRR", 
                 method = "MH", 
                 fixed = TRUE, 
                 random = TRUE, 
                 method.tau = "PM", 
                 method.random.ci = "HK", 
                 title = "Eating Disorder Prevention")

summary(m.inc)
```

## Correlations, Means and Proportions
See web pages:  
https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/pooling-es.html#pooling-cor


# References
- https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/
- Bakbergenuly, Ilyas, David C. Hoaglin, and Elena Kulinskaya. 2020. “Methods for Estimating Between-Study Variance and Overall Effect in Meta-Analysis of Odds Ratios.” Research Synthesis Methods 11(3): 426–42. doi:10.1002/jrsm.1404.
