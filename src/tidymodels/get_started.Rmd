---
title: "GET STARTED"
subtitle: "vignettes"
author: "Maxwell"
date: '`r Sys.Date()`'
# bibliography: references.bib
# link-citations: true
# zotero: "My Library"
# abstract: \singlespacing Abstract which has to be long enough to 
#   take multiple lines otherwise one does not see the effect of single-spacing.
output: 
    html_document:
        number_sections: TRUE
        fig_caption: TRUE
        toc: TRUE
        toc_depth: 5
        toc_float: TRUE
        theme:
            bootswatch: minty
            # bootswatch: cosmo
        highlight: espresso  # espresso, tango, zenburn
        code_folding: show
        # code_download: TRUE
        fig_width: 15
editor_options: 
    chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
# knitr::opts_knit$set(root.dir = ".")  # modify with the location of code
```

----

# Preparations {.tabset .tabset-fade .tabset-pills}

## Packages

```{r Packages, echo=TRUE, message=FALSE}
# Data manipulation
library(tidyverse)
library(data.table)
library(janitor)  # janitor::row_to_names()
library(DT)
library(stringr)
library(lubridate)

# Visualisation
library(ggplot2)
library(ggalt)  # geom_encircle
library(patchwork)
library(broman)  # plot_crayons()
library(ggsci)  # Journal palette
library(rcartocolor)  # display_carto_all(); https://bit.ly/3Itq5kB
library(extrafont)  # "Candara"
library(dotwhisker)

# Descriptive Statistics
library(mice)
library(ggmice)  # see src/imputation/ggmice_XX.Rmd
library(psych)
library(gtsummary)
library(summarytools)

# ML
library(tidymodels)
library(broom.mixed)
tidymodels::tidymodels_prefer()  # override conflicting methods of other pkgs
```

## Environment

```{r Environment, echo=TRUE, message=FALSE}
source(file = "utility/environments.R")
source(file = "utility/helper_functions.R")
```

# Build models {.tabset .tabset-fade .tabset-pills}
## Dataset
```{r}
urchins <- read_csv("https://tidymodels.org/start/models/urchins.csv") 
urchins <- urchins %>% 
    setNames(c("food_regime", "initial_volume", "width")) %>%
    mutate(food_regime = factor(food_regime, levels = c("Initial", "Low", "High")))

glimpse(urchins)
```

## Simple EDA
```{r}
ggplot(urchins, aes(x = initial_volume, 
                    y = width, 
                    group = food_regime, 
                    col = food_regime)) + 
    geom_point() + 
    geom_smooth(method = lm, se = FALSE) + 
    scale_color_npg(alpha = 0.7)
```


## Training
```{r}
lin.reg.fit <- linear_reg() %>% 
    fit(width ~ initial_volume * food_regime, data = urchins)
lm.tidy <- lin.reg.fit%>% tidy()
lm.tidy
```

A dot.whisker function used for a trained model
```{r}
lm.tidy %>% dwplot(
    dot_args = list(size = 2, color = "black"), 
    whisker_args = list(color = "black"), 
    vline = geom_vline(xintercept = 0, colour = "grey50", linetype = 2)
)
```

## Testing
```{r}
new_points <- expand.grid(food_regime = c("Initial", "Low", "High"), 
                          initial_volume = 20)
new_points
```
```{r}
mean_pred <- predict(lin.reg.fit, new_data = new_points)
mean_pred

conf_int_pred <- predict(lin.reg.fit, 
                         new_data = new_points, 
                         type = "conf_int")
conf_int_pred
plot_data <- 
    new_points %>% 
    bind_cols(mean_pred) %>% 
    bind_cols(conf_int_pred)

# and plot:
ggplot(plot_data, aes(x = food_regime)) + 
    geom_point(aes(y = .pred)) + 
    geom_errorbar(aes(ymin = .pred_lower, 
                      ymax = .pred_upper), 
                  width = .2) + 
    labs(y = "urchin size")
```


# Preprocess data with recipes {.tabset .tabset-fade .tabset-pills}
Before training the model, we can use a recipe to create a few new predictors and conduct some preprocessing required by the model.
## The NY Flight Data
```{r}
library(nycflights13)
library(skimr)

set.seed(2023)

flight_data <- flights %>% 
    mutate(
        arr_delay = factor(ifelse(arr_delay >= 30, "late", "on_time")), 
        date = lubridate::as_date(time_hour)
    ) %>% 
    inner_join(weather, by = c("origin", "time_hour")) %>% 
    select(dep_time, flight, origin, dest, air_time, 
           distance, carrier, date, arr_delay, time_hour) %>% 
    na.omit() %>% 
    mutate_if(is.character, as.factor)
```

## Simple EDA with skimr
```{r}
flight_data %>% skimr::skim(dest, carrier)
```
```{r}
flight_data %>% dfSummary() %>% stview(file = "output/get-started_eda-1.html")
```


## Data Splitting
```{r}
set.seed(2023)
data_split <- initial_split(flight_data, prop = 3/4)
train_data <- training(data_split)
test_data  <- testing(data_split)
```

## Create Recipe and Roles
- A formula: Any variable on the left-hand side of the tilde (~) is considered the model outcome (here, arr_delay). On the right-hand side of the tilde are the predictors.
- The data: A recipe is associated with the data set used to create the model. It is only used to catalog the names of the variables and their types, like factors, integers, dates, etc.
```{r}
# Whereas our formula included all variables in the training set other than arr_delay as predictors, "ID" in update_role tells the recipe to keep these two variables but not use them as either outcomes or predictors.
flights_rec <- recipe(arr_delay ~ ., data = train_data) %>% 
    update_role(flight, time_hour, new_role = "ID")
class(flights_rec)
summary(flights_rec)
```

## Create Features
- Unlike the standard model formula methods in R, a recipe does not automatically create these dummy variables for you. You need to tell your recipe to add this step.  
- Nominal variables are data whose levels are labels or descriptions, and which cannot be ordered. Examples of nominal variables are gender, school, and yes/no questions.  
- `step_zv()` will remove columns from the data when the training set data have a single value, so it is added to the recipe after `step_dummy()`.
```{r}
flights_rec <- 
    recipe(arr_delay ~ ., data = train_data) %>% 
    update_role(flight, time_hour, new_role = "ID") %>% 
    step_date(date, features = c("dow", "month")) %>% 
    step_holiday(date, 
                 holidays = timeDate::listHolidays("US"), 
                 keep_original_cols = FALSE) %>% 
    step_dummy(all_factor_predictors()) %>% 
    step_zv(all_predictors())  # remove zero-variance predictor (e.g. LEX in dest var)
summary(flights_rec)
```

## Fit A Model With A Recipe
- A simple process to use a recipe class object is applying `prep()` and `bake()`. A bake function returns a tibble class object.
- To extract the model or recipe objects from the workflow, you can use the helper functions `extract_fit_parsnip()` and `extract_recipe()`.
```{r}
lr_mod <- logistic_reg() %>% set_engine("glm")
```
```{r}
flights_wflow <- 
  workflow() %>% 
  add_model(lr_mod) %>% 
  add_recipe(flights_rec)

flights_wflow
```
```{r}
flights_fit <- 
    flights_wflow %>% 
    fit(data = train_data)
```
```{r}
flights_fit %>% 
    extract_fit_parsnip() %>% 
    tidy()
```

## Use A Trained Workflow To Predict
- To get the predicted class probabilities, specify `type = "prob"` when we use predict() or use `augment()` with the model plus test data to save them together
```{r}
predict(flights_fit, new_data = test_data, type = "prob")
```
```{r}
flights_aug <- 
    augment(flights_fit, test_data)

flights_aug %>%
    select(arr_delay, time_hour, flight, .pred_class, .pred_on_time)
```

```{r}
p <- flights_aug %>% 
    roc_curve(truth = arr_delay, .pred_late) %>% 
    autoplot() + 
    theme(text = element_text(family = font.base))
p
```

